{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv_file(csv_file_path, *database_lists):\n",
    "    \"\"\"\n",
    "    Combine multiple lists of databases, remove duplicates based on URL, and write the results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): Path to the CSV file to be created/updated.\n",
    "        *database_lists (list of dicts): Variable number of lists containing database information.\n",
    "    \"\"\"\n",
    "    # Combine all provided database lists into one, using the URL as a unique identifier to remove duplicates\n",
    "    combined_databases = {db['URL']: db for database_list in database_lists for db in database_list}.values()\n",
    "    \n",
    "    # Write the combined list to the CSV file\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\n",
    "            \"Paper Title\", \"Received Date\", \"Published Date\", \"Name of Journal\",\n",
    "            \"First Author\", \"First Author Affiliation\", \"First Author Email\", \n",
    "            \"Second Author\", \"Second Author Affiliation\", \"Second Author Email\",\n",
    "            \"Third Author\", \"Third Author Affiliation\", \"Third Author Email\",\n",
    "            \"Corresponding Author\", \"Corresponding Author Email\",\n",
    "            \"volume\", \"Number\", \"Article Number\", \"DOI\", \"Abstract\"\n",
    "            ])\n",
    "        writer.writeheader()\n",
    "        for db in combined_databases:\n",
    "            writer.writerow(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use template below to create new row in dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use format below to update above table. Use following prompt to search journals using ChatGPT:\n",
    "\n",
    "List all peer reviewed paper from elsivier published in last 50 years in the format below. Exclude [] in the code.\n",
    "{\n",
    "    \"Paper Title\": \"\",\n",
    "    \"Received Date\": \" \",\n",
    "    \"Published Date\": \" \",\n",
    "    \"Name of Journal\": \" \",\n",
    "    \"First Author\": \" \",\n",
    "    \"First Author Affiliation\":, \" \"\n",
    "    \"First Author Email\": \" \", \n",
    "    \"Second Author\": \" \",\n",
    "    \"Second Author Affiliation\": \" \",\n",
    "    \"Second Author Email\": \" \",\n",
    "    \"Third Author\": \" \",\n",
    "    \"Third Author Affiliation\": \" \",\n",
    "    \"Third Author Email\": \" \",\n",
    "    \"KeyWord1\": \" \",\n",
    "    \"KeyWord2\": \" \",\n",
    "    \"KeyWord3\": \" \",\n",
    "    \"KeyWord4\": \" \",\n",
    "    \"KeyWord5\": \" \",\n",
    "    \"KeyWord6\": \" \",\n",
    "    \"Volume\": \" \",\n",
    "    \"Number\": \" \",\n",
    "    \"Article Number\": \" \",\n",
    "    \"DOI\": \" \",\n",
    "    \"Abstract\": \" \"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_scopus_api_key = \"f67ff601f6de466a22ca3c340044d507\"\n",
    "api_key = 'f67ff601f6de466a22ca3c340044d507'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your new or verified API key\n",
    "api_key = \"your_scopus_api_key\"\n",
    "base_url = \"https://api.elsevier.com/content/search/scopus\"\n",
    "\n",
    "headers = {\n",
    "    'X-ELS-APIKey': api_key,\n",
    "    'Accept': 'application/json'\n",
    "}\n",
    "\n",
    "# Initialize the papers list\n",
    "papers = []\n",
    "\n",
    "# Search query for peer-reviewed papers from Elsevier in the last 10 years\n",
    "params = {\n",
    "    'query': 'PUBYEAR > 2014',\n",
    "    'count': 25,\n",
    "    'sort': 'date',\n",
    "    'start': 0\n",
    "}\n",
    "\n",
    "response = requests.get(base_url, headers=headers, params=params)\n",
    "\n",
    "# Checking the response status and handling errors\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    entries = data.get('search-results', {}).get('entry', [])\n",
    "\n",
    "    for entry in entries:\n",
    "        # Extracting author details with safer access\n",
    "        authors = entry.get('author', [])\n",
    "        affiliations = entry.get('affiliation', [])\n",
    "        authkeywords = entry.get('authkeywords', [])\n",
    "\n",
    "        # Check for corresponding author in the response\n",
    "        corresponding_author = entry.get(\n",
    "            'corresponding-author', {}) if 'corresponding-author' in entry else {}\n",
    "\n",
    "        # Safe access to list elements\n",
    "        def safe_get(lst, index, default_value):\n",
    "            try:\n",
    "                return lst[index]\n",
    "            except IndexError:\n",
    "                return default_value\n",
    "\n",
    "        paper = {\n",
    "            \"Paper Title\": entry.get('dc:title', ''),\n",
    "            \"Received Date\": entry.get('prism:coverDisplayDate', ''),\n",
    "            \"Published Date\": entry.get('prism:coverDate', ''),\n",
    "            \"Name of Journal\": entry.get('prism:publicationName', ''),\n",
    "            \"First Author\": safe_get(authors, 0, {}).get('authname', ''),\n",
    "            \"First Author Affiliation\": safe_get(affiliations, 0, {}).get('affilname', ''),\n",
    "            \"First Author Email\": safe_get(authors, 0, {}).get('author-email', ''),\n",
    "            \"Second Author\": safe_get(authors, 1, {}).get('authname', ''),\n",
    "            \"Second Author Affiliation\": safe_get(affiliations, 1, {}).get('affilname', ''),\n",
    "            \"Second Author Email\": safe_get(authors, 1, {}).get('author-email', ''),\n",
    "            \"Third Author\": safe_get(authors, 2, {}).get('authname', ''),\n",
    "            \"Third Author Affiliation\": safe_get(affiliations, 2, {}).get('affilname', ''),\n",
    "            \"Third Author Email\": safe_get(authors, 2, {}).get('author-email', ''),\n",
    "            \"Corresponding Author\": corresponding_author.get('authname', ''),\n",
    "            \"Corresponding Author Email\": corresponding_author.get('author-email', ''),\n",
    "            \"KeyWord1\": safe_get(authkeywords, 0, ''),\n",
    "            \"KeyWord2\": safe_get(authkeywords, 1, ''),\n",
    "            \"KeyWord3\": safe_get(authkeywords, 2, ''),\n",
    "            \"KeyWord4\": safe_get(authkeywords, 3, ''),\n",
    "            \"KeyWord5\": safe_get(authkeywords, 4, ''),\n",
    "            \"KeyWord6\": safe_get(authkeywords, 5, ''),\n",
    "            \"Volume\": entry.get('prism:volume', ''),\n",
    "            \"Number\": entry.get('prism:issueIdentifier', ''),\n",
    "            \"Article Number\": entry.get('dc:identifier', ''),\n",
    "            \"DOI\": entry.get('prism:doi', ''),\n",
    "            \"Abstract\": entry.get('dc:description', '')\n",
    "        }\n",
    "        papers.append(paper)\n",
    "\n",
    "    # Display the collected papers\n",
    "    for paper in papers:\n",
    "        print(paper)\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve data:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to save the CSV\n",
    "csv_file_path = \"Elsivier Papers.csv\"\n",
    "\n",
    "# Call the function with any number of database lists\n",
    "update_csv_file(csv_file_path, bibs)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' has been updated.\")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Get the dimensions of the DataFrame\n",
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(f\"The CSV file has {num_rows} rows and {num_columns} columns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
